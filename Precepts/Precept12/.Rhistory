g <- regsubsets(wgt~., data=b, really.big=F, method='exhaustive', nvmax=12)
# Chunk 1: setup
knitr::opts_chunk$set(fig.align="center", fig.height=5.5, fig.width=6, collapse=TRUE, comment="", prompt=FALSE, echo = TRUE, cache=TRUE, autodep=TRUE, tidy=FALSE, message = F, warning = F, tidy.opts=list(width.cutoff=60))
options(width=63)
# Chunk 2
library(openintro)
dim(bdims)
names(bdims)
# Creating dataset for the demo
d = bdims[,c("wgt", "sex", "age", "sho.gi", "che.gi",
"thi.gi", "bic.gi", "for.gi", "kne.gi")]
# See descriptions of the interested variables
?bdims
str(d)
# sex is not a factor when it is supposed to be
# a categorical variable; let's change it to be
# a factor
d$sex = as.factor(d$sex)
str(d)
# The data types of other variables seem correct.
# If needed, we can always modify the data types later.
# Chunk 3
d$sex = as.factor(d$sex)
library(ggplot2)
library(GGally)
# Instructors, please explain what the graph and the numbers
# on the graph mean
ggpairs(d[, c(2:9, 1)], aes(colour = sex, alpha = 0.4),
upper = list(continuous = wrap("cor", size = 2.2)),
lower = list(continuous = wrap("points", alpha = 0.3, size=0.1))) +
theme(axis.text.x = element_text(angle = 45))
# Chunk 4
library(leaps)
# library(car)
str(d)
# For each given number of predictors, find the best model
g <- regsubsets(wgt~., data=d, really.big=F, method='exhaustive', nvmax=8)
# set really.big=T if your design matrix is very big;
# can change option for method to forward selection, backward selection or sequential replacement to search when dataset is very big.
plot(summary(g)$bic,
main = 'BIC for best model for each given number of predictors',
xlab = 'Given number of predictors',
ylab = 'BIC')
plot(summary(g)$adjr2, main = 'Adjusted R-square for best model \nfor each given number of predictors', xlab = 'Given number of predictors', ylab = 'Adjusted R-square') # adjusted R^2 chooses a different model
plot(summary(g)$cp, main = 'Mallows Cp for best model for each given number of predictors', xlab = 'Given number of predictors', ylab = 'Mallows Cp')
abline(a = 1, b = 1, lty = "dashed")
# Chunk 5
summary.g <- summary(g)
# The best model for each number of predictors included in model
as.data.frame(summary.g$outmat)
# Chunk 6
coef(g, id = 4)
coef(g, id = 5)
# Chunk 7
mod1 = lm(wgt ~ sex + che.gi + thi.gi + kne.gi, data=d)
summary(mod1)
mod2 = lm(wgt ~ sex + sho.gi + che.gi + thi.gi + kne.gi, data=d)
summary(mod2)
# Chunk 8
round(vcov(mod1), 4)
round(vcov(mod2), 4)
# Chunk 9
# a correlation(beta_i, beta_j) close to 1 or -1 is bad since it implies
# collinearity between X_i and X_j columns;
# we do not want to see high values for the correlations.
# The correlation between beta_hat.sho.gi and beta_hat.che.gi is
vcov(mod2)["sho.gi", "che.gi"]/sqrt(vcov(mod2)["sho.gi", "sho.gi"])/sqrt(vcov(mod2)["che.gi", "che.gi"])
# this is high enough to get our attention
# Chunk 10
plot(mod1, which=1:2)
hist(mod1$residuals, freq=F, breaks=30)
# Chunk 11
ggpairs(d[,c('sex', 'che.gi', 'thi.gi','kne.gi', 'wgt')],
upper = list(continuous = wrap("cor", size = 3)),
lower = list(continuous = wrap("points", alpha = 0.3, size=0.1)),
aes(colour = sex, alpha = 0.4))
# Chunk 12
mod3 = lm(wgt ~ sex + che.gi + thi.gi + kne.gi + sex:thi.gi, data=d)
# compare R-squared's
summary(mod3)
summary(mod1)
# Chunk 13
# look at p-value which is on the borderline of .05
anova(mod1, mod3)
# Chunk 14
# Compare BICs
extractAIC(mod1, k=log(dim(d)[1]))
extractAIC(mod3, k=log(dim(d)[1])) # This actually increase BIC
# Chunk 15
head(model.matrix(mod1))
colnames(model.matrix(mod1))
# Chunk 16
b = bdims[,c("hgt", "sex", "age", "bii.di", "bit.di", "che.de", "kne.di", "ank.di",
"wai.gi", "nav.gi", "hip.gi", "thi.gi")]
dim(b)
str(b)
b$sex = as.factor(b$sex)
# There are too many variables for plotting them all
# on the same graph, so we will make two graphs
ggpairs(b[,c(2, 3:7, 1)], aes(colour = sex, alpha = 0.4),
upper = list(continuous = wrap("cor", size = 2.4)),
lower = list(continuous = wrap("points", alpha = 0.3, size=0.1))) +
theme(axis.text.x = element_text(angle = 45, size = 6))
ggpairs(b[,c(2, 8:12, 1)], aes(colour = sex, alpha = 0.4),
upper = list(continuous = wrap("cor", size = 2.4)),
lower = list(continuous = wrap("points", alpha = 0.3, size=0.1))) +
theme(axis.text.x = element_text(angle = 45, size = 6))
g <- regsubsets(wgt~., data=b, really.big=F, method='exhaustive', nvmax=12)
g <- regsubsets(hgt~., data=b, really.big=F, method='exhaustive', nvmax=12)
g <- regsubsets(hgt~., data=b, really.big=F, method='exhaustive', nvmax=12)
plot(summary(g)$bic,
main = 'BIC for best model for each given number of predictors',
xlab = 'Given number of predictors',
ylab = 'BIC')
plot(summary(g)$adjr2, main = 'Adjusted R-square for best model \nfor each given number of predictors', xlab = 'Given number of predictors', ylab = 'Adjusted R-square') # adjusted R^2 chooses a different model
plot(summary(g)$cp, main = 'Mallows Cp for best model for each given number of predictors', xlab = 'Given number of predictors', ylab = 'Mallows Cp')
abline(a = 1, b = 1, lty = "dashed")
coef(g, id = 8)
coef(g, id = 9)
mod1 = lm(hgt ~ sex + age + bii.di + bit.di + che.de + ank.di + wai.gi + thi.gi, data=b)
summary(mod1)
mod2 = lm(hgt ~ sex + age + bii.di + bit.di + che.de + ank.di + wai.gi + hip.gi + thi.gi, data=b)
summary(mod2)
round(vcov(mod1), 4)
round(vcov(mod2), 4)
vcov(mod2)["hip.gi", "thi.gi"]/sqrt(vcov(mod2)["hip.gi", "hip.gi"])/sqrt(vcov(mod2)["thi.gi", "thi.gi"])
plot(mod1, which=1:2)
summary(mod1)
anova(mod1, mod3)
g <- regsubsets(hgt~., data=b, really.big=F, method='exhaustive', nvmax=12)
plot(summary(g)$bic,
main = 'BIC for best model for each given number of predictors',
xlab = 'Given number of predictors',
ylab = 'BIC')
plot(summary(g)$adjr2, main = 'Adjusted R-square for best model \nfor each given number of predictors', xlab = 'Given number of predictors', ylab = 'Adjusted R-square') # adjusted R^2 chooses a different model
plot(summary(g)$cp, main = 'Mallows Cp for best model for each given number of predictors', xlab = 'Given number of predictors', ylab = 'Mallows Cp')
abline(a = 1, b = 1, lty = "dashed")
coef(g, id = 8)
coef(g, id = 9)
mod1 = lm(hgt ~ sex + age + bii.di + bit.di + che.de + ank.di + wai.gi + thi.gi, data=b)
summary(mod1)
mod2 = lm(hgt ~ sex + age + bii.di + bit.di + che.de + ank.di + wai.gi + hip.gi + thi.gi, data=b)
summary(mod2)
round(vcov(mod1), 4)
round(vcov(mod2), 4)
vcov(mod2)["hip.gi", "thi.gi"]/sqrt(vcov(mod2)["hip.gi", "hip.gi"])/sqrt(vcov(mod2)["thi.gi", "thi.gi"])
# -0.68945 is high enough to attract attention
plot(mod1, which=1:2)
mod3 = lm(hgt ~ sex + age + bii.di + bit.di + che.de + ank.di + wai.gi + thi.gi + sex:thi.gi, data=b)
summary(mod3)
summary(mod1)
anova(mod1, mod3)
