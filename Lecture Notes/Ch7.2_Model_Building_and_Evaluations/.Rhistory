library(DiagrammeR)
DiagrammeR("graph TB;
A(Our Dataset)-->B[Non-test set];
A(Our Dataset)-->C[Test set];
B[Non-test set]-->D[Subset 1];
B[Non-test set]-->E[Subset 2];
B[Non-test set]-->F[Subset 3];
B[Non-test set]-->G[Subset 4];
B[Non-test set]-->H[Subset 5];")
# Chunk 5
par(mfrow=c(2,2))
# plot 1
plot(x=rnorm(200), y=rnorm(200), ylab="residuals", xlab="fitted values", main='uncorrelated residuals', cex.main=.9)
abline(h=0, col='red')
# plot 2
x = rnorm(200)
y = x^2 + rnorm(200, mean=.1, sd=1)
plot(x=x, y=y, ylab="residuals", xlab="fitted values", main='dependent residuals', cex.main=.9)
abline(h=0, col='red')
# plot 3
x = rnorm(200)
y = -x + rnorm(200, mean=0, sd=1)
plot(x=x, y=y, ylab="residuals", xlab="fitted values", main='dependent residuals', cex.main=.9)
abline(h=0, col='red')
# plot 4
x = abs(rnorm(200, sd=5))
y = x + rnorm(200, mean=.1, sd=x)
plot(x=x, y=y, ylab="residuals", xlab="fitted values", main='non-constant var(residuals)', cex.main=.9)
abline(h=0, col='red')
# Chunk 6
ins = read.csv('/Users/billhaarlow/Desktop/SML201/Lecture Notes/Ch7.2_Model_Building_and_Evaluations/insurance.csv')
mod_age_smk = lm(charges ~ age + smoker, data = ins)
summary(mod_age_smk)
# Chunk 7
plot(mod_age_smk, which=1)
# Chunk 8
# Checking Normality of the residuals
plot(mod_age_smk, which=2)
# Chunk 9
hist(mod_age_smk$residuals, breaks=30, freq = F, main='Histogram of residuals',
xlab = 'residuals for lm(charges ~ age + smoker)')
# Chunk 10
library(openintro)
dim(bdims)
names(bdims)
# Creating dataset for the demo
d = bdims[,c("wgt", "sex", "age", "sho.gi", "che.gi",
"thi.gi", "bic.gi", "for.gi", "kne.gi")]
dim(d)
# See descriptions of the interested variables
?bdims
str(d)
# sex is not a factor when it is supposed to be
# a categorical variable; let's change it to be
# a factor
d$sex = as.factor(d$sex)
str(d)
# The data types of other variables seem correct.
# If needed, we can always modify the data types later.
# Chunk 11
d$sex = as.factor(d$sex)
library(ggplot2)
library(GGally)
# Instructors, please explain what the graph and the numbers
# on the graph mean
ggpairs(d[, c(2:9, 1)], aes(colour = sex, alpha = 0.4),
upper = list(continuous = wrap("cor", size = 2.2)),
lower = list(continuous = wrap("points", alpha = 0.3, size=0.1))) +
theme(axis.text.x = element_text(angle = 45))
# Chunk 12
library(config)
install.packages("data.table")
library(car)
str(d)
# For each given number of predictors, find the best model
g <- regsubsets(wgt~., data=d, really.big=F, method='exhaustive', nvmax=8)
# set really.big=T if your design matrix is very big;
# can change option for method to forward selection, backward selection or sequential replacement to search when dataset is very big.
plot(summary(g)$bic,
main = 'BIC for best model for each given number of predictors',
xlab = 'Given number of predictors',
ylab = 'BIC')
plot(summary(g)$adjr2, main = 'Adjusted R-square for best model \nfor each given number of predictors', xlab = 'Given number of predictors', ylab = 'Adjusted R-square') # adjusted R^2 chooses a different model
plot(summary(g)$cp, main = 'Mallows Cp for best model for each given number of predictors', xlab = 'Given number of predictors', ylab = 'Mallows Cp')
abline(a = 1, b = 1, lty = "dashed")
# Chunk 13
summary.g <- summary(g)
# The best model for each number of predictors included in model
as.data.frame(summary.g$outmat)
# Chunk 14
coef(g, id = 4)
coef(g, id = 5)
# Chunk 15
mod1 = lm(wgt ~ sex + che.gi + thi.gi + kne.gi, data=d)
summary(mod1)
mod2 = lm(wgt ~ sex + sho.gi + che.gi + thi.gi + kne.gi, data=d)
summary(mod2)
# Chunk 16
round(vcov(mod1), 4)
round(vcov(mod2), 4)
# Chunk 17
# a correlation(beta_i, beta_j) close to 1 or -1 is bad since it implies
# collinearity between X_i and X_j columns;
# we do not want to see high values for the correlations.
# The correlation between beta_hat.sho.gi and beta_hat.che.gi is
vcov(mod2)["sho.gi", "che.gi"]/sqrt(vcov(mod2)["sho.gi", "sho.gi"])/sqrt(vcov(mod2)["che.gi", "che.gi"])
# this is high enough to get our attention
# Chunk 18
plot(mod1, which=1:2)
# which = 1 gives the residuals v.s. fitted values scatterplot
# which = 2 gives the qqplot for the residuals
hist(mod1$residuals, freq=F, breaks=30)
# Chunk 19
# define a function to make prediction for an object that is the output of regsubsets()
predict.reg = function(object,newdata,id){
form = as.formula(object$call[[2]]) # Extract the formula used when we called regsubsets()
mat = model.matrix(form,newdata)    # Build the model matrix
coefi = coef(object,id=id)          # Extract the coefficients of the id'th model
xvars = names(coefi)                # Pull out the names of the predictors used in the ith model
mat[,xvars]%*%coefi               # Make predictions using matrix multiplication
}
# Chunk 20
set.seed(78924)
ind = sample(1:nrow(d), nrow(d)*.8, replace = F)
train = d[ind,]
validation = d[-ind,]
g.train <- regsubsets(wgt~., data=train, really.big=F, method='exhaustive', nvmax=8)
predict.reg(object = g.train, newdata = validation,id = 4)
library(compiler)
library(config)
install.packages("data.table")
library(leaps)
library(car)
str(d)
# For each given number of predictors, find the best model
g <- regsubsets(wgt~., data=d, really.big=F, method='exhaustive', nvmax=8)
# set really.big=T if your design matrix is very big;
# can change option for method to forward selection, backward selection or sequential replacement to search when dataset is very big.
plot(summary(g)$bic,
main = 'BIC for best model for each given number of predictors',
xlab = 'Given number of predictors',
ylab = 'BIC')
plot(summary(g)$adjr2, main = 'Adjusted R-square for best model \nfor each given number of predictors', xlab = 'Given number of predictors', ylab = 'Adjusted R-square') # adjusted R^2 chooses a different model
plot(summary(g)$cp, main = 'Mallows Cp for best model for each given number of predictors', xlab = 'Given number of predictors', ylab = 'Mallows Cp')
abline(a = 1, b = 1, lty = "dashed")
library(compiler)
library(config)
library(pkgconfig)
install.packages("data.table")
library(leaps)
library(car)
str(d)
# For each given number of predictors, find the best model
g <- regsubsets(wgt~., data=d, really.big=F, method='exhaustive', nvmax=8)
# set really.big=T if your design matrix is very big;
# can change option for method to forward selection, backward selection or sequential replacement to search when dataset is very big.
plot(summary(g)$bic,
main = 'BIC for best model for each given number of predictors',
xlab = 'Given number of predictors',
ylab = 'BIC')
plot(summary(g)$adjr2, main = 'Adjusted R-square for best model \nfor each given number of predictors', xlab = 'Given number of predictors', ylab = 'Adjusted R-square') # adjusted R^2 chooses a different model
plot(summary(g)$cp, main = 'Mallows Cp for best model for each given number of predictors', xlab = 'Given number of predictors', ylab = 'Mallows Cp')
abline(a = 1, b = 1, lty = "dashed")
library(data.table)
library(car)
library(data.table)
library(leaps)
library(car)
str(d)
# For each given number of predictors, find the best model
g <- regsubsets(wgt~., data=d, really.big=F, method='exhaustive', nvmax=8)
# set really.big=T if your design matrix is very big;
# can change option for method to forward selection, backward selection or sequential replacement to search when dataset is very big.
plot(summary(g)$bic,
main = 'BIC for best model for each given number of predictors',
xlab = 'Given number of predictors',
ylab = 'BIC')
plot(summary(g)$adjr2, main = 'Adjusted R-square for best model \nfor each given number of predictors', xlab = 'Given number of predictors', ylab = 'Adjusted R-square') # adjusted R^2 chooses a different model
plot(summary(g)$cp, main = 'Mallows Cp for best model for each given number of predictors', xlab = 'Given number of predictors', ylab = 'Mallows Cp')
abline(a = 1, b = 1, lty = "dashed")
library(car)
# Chunk 1: setup
knitr::opts_chunk$set(fig.align="center", fig.height=5.5, fig.width=6, collapse=TRUE, comment="", prompt=F, echo = TRUE, cache=TRUE, autodep=TRUE, cache.comments=FALSE,
tidy=TRUE, tidy.opts=list(width.cutoff=60))
options(width=63)
# Chunk 2
library(DiagrammeR)
DiagrammeR("graph TB;
A(Our Dataset)-->B[Non-test set];
A(Our Dataset)-->C[Test set];")
# Chunk 3
library(DiagrammeR)
DiagrammeR("graph TB;
A(Our Dataset)-->B[Non-test set];
A(Our Dataset)-->C[Test set];
B[Non-test set]-->D[Training set];
B[Non-test set]-->E[Validation set];")
# Chunk 4
library(DiagrammeR)
DiagrammeR("graph TB;
A(Our Dataset)-->B[Non-test set];
A(Our Dataset)-->C[Test set];
B[Non-test set]-->D[Subset 1];
B[Non-test set]-->E[Subset 2];
B[Non-test set]-->F[Subset 3];
B[Non-test set]-->G[Subset 4];
B[Non-test set]-->H[Subset 5];")
# Chunk 5
par(mfrow=c(2,2))
# plot 1
plot(x=rnorm(200), y=rnorm(200), ylab="residuals", xlab="fitted values", main='uncorrelated residuals', cex.main=.9)
abline(h=0, col='red')
# plot 2
x = rnorm(200)
y = x^2 + rnorm(200, mean=.1, sd=1)
plot(x=x, y=y, ylab="residuals", xlab="fitted values", main='dependent residuals', cex.main=.9)
abline(h=0, col='red')
# plot 3
x = rnorm(200)
y = -x + rnorm(200, mean=0, sd=1)
plot(x=x, y=y, ylab="residuals", xlab="fitted values", main='dependent residuals', cex.main=.9)
abline(h=0, col='red')
# plot 4
x = abs(rnorm(200, sd=5))
y = x + rnorm(200, mean=.1, sd=x)
plot(x=x, y=y, ylab="residuals", xlab="fitted values", main='non-constant var(residuals)', cex.main=.9)
abline(h=0, col='red')
# Chunk 6
ins = read.csv('/Users/billhaarlow/Desktop/SML201/Lecture Notes/Ch7.2_Model_Building_and_Evaluations/insurance.csv')
mod_age_smk = lm(charges ~ age + smoker, data = ins)
summary(mod_age_smk)
# Chunk 7
plot(mod_age_smk, which=1)
# Chunk 8
# Checking Normality of the residuals
plot(mod_age_smk, which=2)
# Chunk 9
hist(mod_age_smk$residuals, breaks=30, freq = F, main='Histogram of residuals',
xlab = 'residuals for lm(charges ~ age + smoker)')
# Chunk 10
library(openintro)
dim(bdims)
names(bdims)
# Creating dataset for the demo
d = bdims[,c("wgt", "sex", "age", "sho.gi", "che.gi",
"thi.gi", "bic.gi", "for.gi", "kne.gi")]
dim(d)
# See descriptions of the interested variables
?bdims
str(d)
# sex is not a factor when it is supposed to be
# a categorical variable; let's change it to be
# a factor
d$sex = as.factor(d$sex)
str(d)
# The data types of other variables seem correct.
# If needed, we can always modify the data types later.
# Chunk 11
d$sex = as.factor(d$sex)
library(ggplot2)
library(GGally)
# Instructors, please explain what the graph and the numbers
# on the graph mean
ggpairs(d[, c(2:9, 1)], aes(colour = sex, alpha = 0.4),
upper = list(continuous = wrap("cor", size = 2.2)),
lower = list(continuous = wrap("points", alpha = 0.3, size=0.1))) +
theme(axis.text.x = element_text(angle = 45))
library(leaps)
library(car)
library(leaps)
library(car)
str(d)
# For each given number of predictors, find the best model
g <- regsubsets(wgt~., data=d, really.big=F, method='exhaustive', nvmax=8)
# set really.big=T if your design matrix is very big;
# can change option for method to forward selection, backward selection or sequential replacement to search when dataset is very big.
plot(summary(g)$bic,
main = 'BIC for best model for each given number of predictors',
xlab = 'Given number of predictors',
ylab = 'BIC')
plot(summary(g)$adjr2, main = 'Adjusted R-square for best model \nfor each given number of predictors', xlab = 'Given number of predictors', ylab = 'Adjusted R-square') # adjusted R^2 chooses a different model
plot(summary(g)$cp, main = 'Mallows Cp for best model for each given number of predictors', xlab = 'Given number of predictors', ylab = 'Mallows Cp')
abline(a = 1, b = 1, lty = "dashed")
# Chunk 1: setup
knitr::opts_chunk$set(fig.align="center", fig.height=5.5, fig.width=6, collapse=TRUE, comment="", prompt=F, echo = TRUE, cache=TRUE, autodep=TRUE, cache.comments=FALSE,
tidy=TRUE, tidy.opts=list(width.cutoff=60))
options(width=63)
# Chunk 2
library(DiagrammeR)
DiagrammeR("graph TB;
A(Our Dataset)-->B[Non-test set];
A(Our Dataset)-->C[Test set];")
# Chunk 3
library(DiagrammeR)
DiagrammeR("graph TB;
A(Our Dataset)-->B[Non-test set];
A(Our Dataset)-->C[Test set];
B[Non-test set]-->D[Training set];
B[Non-test set]-->E[Validation set];")
# Chunk 4
library(DiagrammeR)
DiagrammeR("graph TB;
A(Our Dataset)-->B[Non-test set];
A(Our Dataset)-->C[Test set];
B[Non-test set]-->D[Subset 1];
B[Non-test set]-->E[Subset 2];
B[Non-test set]-->F[Subset 3];
B[Non-test set]-->G[Subset 4];
B[Non-test set]-->H[Subset 5];")
# Chunk 5
par(mfrow=c(2,2))
# plot 1
plot(x=rnorm(200), y=rnorm(200), ylab="residuals", xlab="fitted values", main='uncorrelated residuals', cex.main=.9)
abline(h=0, col='red')
# plot 2
x = rnorm(200)
y = x^2 + rnorm(200, mean=.1, sd=1)
plot(x=x, y=y, ylab="residuals", xlab="fitted values", main='dependent residuals', cex.main=.9)
abline(h=0, col='red')
# plot 3
x = rnorm(200)
y = -x + rnorm(200, mean=0, sd=1)
plot(x=x, y=y, ylab="residuals", xlab="fitted values", main='dependent residuals', cex.main=.9)
abline(h=0, col='red')
# plot 4
x = abs(rnorm(200, sd=5))
y = x + rnorm(200, mean=.1, sd=x)
plot(x=x, y=y, ylab="residuals", xlab="fitted values", main='non-constant var(residuals)', cex.main=.9)
abline(h=0, col='red')
# Chunk 6
ins = read.csv('/Users/billhaarlow/Desktop/SML201/Lecture Notes/Ch7.2_Model_Building_and_Evaluations/insurance.csv')
mod_age_smk = lm(charges ~ age + smoker, data = ins)
summary(mod_age_smk)
# Chunk 7
plot(mod_age_smk, which=1)
# Chunk 8
# Checking Normality of the residuals
plot(mod_age_smk, which=2)
# Chunk 9
hist(mod_age_smk$residuals, breaks=30, freq = F, main='Histogram of residuals',
xlab = 'residuals for lm(charges ~ age + smoker)')
# Chunk 10
library(openintro)
dim(bdims)
names(bdims)
# Creating dataset for the demo
d = bdims[,c("wgt", "sex", "age", "sho.gi", "che.gi",
"thi.gi", "bic.gi", "for.gi", "kne.gi")]
dim(d)
# See descriptions of the interested variables
?bdims
str(d)
# sex is not a factor when it is supposed to be
# a categorical variable; let's change it to be
# a factor
d$sex = as.factor(d$sex)
str(d)
# The data types of other variables seem correct.
# If needed, we can always modify the data types later.
# Chunk 11
d$sex = as.factor(d$sex)
library(ggplot2)
library(GGally)
# Instructors, please explain what the graph and the numbers
# on the graph mean
ggpairs(d[, c(2:9, 1)], aes(colour = sex, alpha = 0.4),
upper = list(continuous = wrap("cor", size = 2.2)),
lower = list(continuous = wrap("points", alpha = 0.3, size=0.1))) +
theme(axis.text.x = element_text(angle = 45))
# Chunk 1: setup
knitr::opts_chunk$set(fig.align="center", fig.height=5.5, fig.width=6, collapse=TRUE, comment="", prompt=F, echo = TRUE, cache=TRUE, autodep=TRUE, cache.comments=FALSE,
tidy=TRUE, tidy.opts=list(width.cutoff=60))
options(width=63)
# Chunk 2
library(DiagrammeR)
DiagrammeR("graph TB;
A(Our Dataset)-->B[Non-test set];
A(Our Dataset)-->C[Test set];")
# Chunk 3
library(DiagrammeR)
DiagrammeR("graph TB;
A(Our Dataset)-->B[Non-test set];
A(Our Dataset)-->C[Test set];
B[Non-test set]-->D[Training set];
B[Non-test set]-->E[Validation set];")
# Chunk 4
library(DiagrammeR)
DiagrammeR("graph TB;
A(Our Dataset)-->B[Non-test set];
A(Our Dataset)-->C[Test set];
B[Non-test set]-->D[Subset 1];
B[Non-test set]-->E[Subset 2];
B[Non-test set]-->F[Subset 3];
B[Non-test set]-->G[Subset 4];
B[Non-test set]-->H[Subset 5];")
# Chunk 5
par(mfrow=c(2,2))
# plot 1
plot(x=rnorm(200), y=rnorm(200), ylab="residuals", xlab="fitted values", main='uncorrelated residuals', cex.main=.9)
abline(h=0, col='red')
# plot 2
x = rnorm(200)
y = x^2 + rnorm(200, mean=.1, sd=1)
plot(x=x, y=y, ylab="residuals", xlab="fitted values", main='dependent residuals', cex.main=.9)
abline(h=0, col='red')
# plot 3
x = rnorm(200)
y = -x + rnorm(200, mean=0, sd=1)
plot(x=x, y=y, ylab="residuals", xlab="fitted values", main='dependent residuals', cex.main=.9)
abline(h=0, col='red')
# plot 4
x = abs(rnorm(200, sd=5))
y = x + rnorm(200, mean=.1, sd=x)
plot(x=x, y=y, ylab="residuals", xlab="fitted values", main='non-constant var(residuals)', cex.main=.9)
abline(h=0, col='red')
# Chunk 6
ins = read.csv('/Users/billhaarlow/Desktop/SML201/Lecture Notes/Ch7.2_Model_Building_and_Evaluations/insurance.csv')
mod_age_smk = lm(charges ~ age + smoker, data = ins)
summary(mod_age_smk)
# Chunk 7
plot(mod_age_smk, which=1)
# Chunk 8
# Checking Normality of the residuals
plot(mod_age_smk, which=2)
# Chunk 9
hist(mod_age_smk$residuals, breaks=30, freq = F, main='Histogram of residuals',
xlab = 'residuals for lm(charges ~ age + smoker)')
# Chunk 10
library(openintro)
dim(bdims)
names(bdims)
# Creating dataset for the demo
d = bdims[,c("wgt", "sex", "age", "sho.gi", "che.gi",
"thi.gi", "bic.gi", "for.gi", "kne.gi")]
dim(d)
# See descriptions of the interested variables
?bdims
str(d)
# sex is not a factor when it is supposed to be
# a categorical variable; let's change it to be
# a factor
d$sex = as.factor(d$sex)
str(d)
# The data types of other variables seem correct.
# If needed, we can always modify the data types later.
# Chunk 11
d$sex = as.factor(d$sex)
library(ggplot2)
library(GGally)
# Instructors, please explain what the graph and the numbers
# on the graph mean
ggpairs(d[, c(2:9, 1)], aes(colour = sex, alpha = 0.4),
upper = list(continuous = wrap("cor", size = 2.2)),
lower = list(continuous = wrap("points", alpha = 0.3, size=0.1))) +
theme(axis.text.x = element_text(angle = 45))
# Chunk 12
library(leaps)
str(d)
# For each given number of predictors, find the best model
g <- regsubsets(wgt~., data=d, really.big=F, method='exhaustive', nvmax=8)
# set really.big=T if your design matrix is very big;
# can change option for method to forward selection, backward selection or sequential replacement to search when dataset is very big.
plot(summary(g)$bic,
main = 'BIC for best model for each given number of predictors',
xlab = 'Given number of predictors',
ylab = 'BIC')
plot(summary(g)$adjr2, main = 'Adjusted R-square for best model \nfor each given number of predictors', xlab = 'Given number of predictors', ylab = 'Adjusted R-square') # adjusted R^2 chooses a different model
plot(summary(g)$cp, main = 'Mallows Cp for best model for each given number of predictors', xlab = 'Given number of predictors', ylab = 'Mallows Cp')
abline(a = 1, b = 1, lty = "dashed")
# Chunk 13
summary.g <- summary(g)
# The best model for each number of predictors included in model
as.data.frame(summary.g$outmat)
# Chunk 14
coef(g, id = 4)
coef(g, id = 5)
# Chunk 15
mod1 = lm(wgt ~ sex + che.gi + thi.gi + kne.gi, data=d)
summary(mod1)
mod2 = lm(wgt ~ sex + sho.gi + che.gi + thi.gi + kne.gi, data=d)
summary(mod2)
# Chunk 16
round(vcov(mod1), 4)
round(vcov(mod2), 4)
# Chunk 17
# a correlation(beta_i, beta_j) close to 1 or -1 is bad since it implies
# collinearity between X_i and X_j columns;
# we do not want to see high values for the correlations.
# The correlation between beta_hat.sho.gi and beta_hat.che.gi is
vcov(mod2)["sho.gi", "che.gi"]/sqrt(vcov(mod2)["sho.gi", "sho.gi"])/sqrt(vcov(mod2)["che.gi", "che.gi"])
# this is high enough to get our attention
# Chunk 18
plot(mod1, which=1:2)
# which = 1 gives the residuals v.s. fitted values scatterplot
# which = 2 gives the qqplot for the residuals
hist(mod1$residuals, freq=F, breaks=30)
# Chunk 19
# define a function to make prediction for an object that is the output of regsubsets()
predict.reg = function(object,newdata,id){
form = as.formula(object$call[[2]]) # Extract the formula used when we called regsubsets()
mat = model.matrix(form,newdata)    # Build the model matrix
coefi = coef(object,id=id)          # Extract the coefficients of the id'th model
xvars = names(coefi)                # Pull out the names of the predictors used in the ith model
mat[,xvars]%*%coefi               # Make predictions using matrix multiplication
}
# Chunk 20
set.seed(78924)
ind = sample(1:nrow(d), nrow(d)*.8, replace = F)
train = d[ind,]
validation = d[-ind,]
g.train <- regsubsets(wgt~., data=train, really.big=F, method='exhaustive', nvmax=8)
predict.reg(object = g.train, newdata = validation,id = 4)
